{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json \n",
    "from hashlib import sha256\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "from google.cloud import storage\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from data_engineering.data_aggregator.image_aggregators import image_files_from_tif_to_augmented_png\n",
    "from data_science.data_manipulation import balanced_class_train_test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jovyan/work/data/big_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import glob\n",
    "\n",
    "logger = logging.getLogger()\n",
    "json_files_dir = root + \"/BigEarthNet-V1.0\"\n",
    "csv_output_dir = root + \"/metadata\"\n",
    "npy_image_dir = root + \"/npy_image_files\"\n",
    "\n",
    "logger.info('test')\n",
    "\n",
    "if not os.path.exists(csv_output_dir):\n",
    "    os.mkdir(csv_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(csv_output_dir + '/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'libfreeimage-3.16.0-linux64.so' was not found on your computer; downloading it now.\n",
      "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/freeimage/libfreeimage-3.16.0-linux64.so (4.6 MB)\n",
      "Downloading: 8192/4830080 bytes (0.2%344064/4830080 bytes (7.1%1015808/4830080 bytes (21.0%1654784/4830080 bytes (34.3%2408448/4830080 bytes (49.9%2867200/4830080 bytes (59.4%3358720/4830080 bytes (69.5%3653632/4830080 bytes (75.6%3997696/4830080 bytes (82.8%4784128/4830080 bytes (99.0%4830080/4830080 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /root/.imageio/freeimage/libfreeimage-3.16.0-linux64.so.\n"
     ]
    }
   ],
   "source": [
    "imageio.plugins.freeimage.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_automl_dataset = pd.read_csv('/app/data_science/google_automl_cloud_and_shadow_dataset_small.csv')\n",
    "google_automl_dataset['image_prefix'] = google_automl_dataset['gcs_uri'].str.split('/').apply(lambda x: x[-1].replace(\".png\", \"\"))\n",
    "google_automl_dataset = google_automl_dataset.set_index('image_prefix', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data to the dataset\n",
    "df = pd.read_csv(root + \"/metadata/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 12989 len(valid) 1571 len(test) 1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18560"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.set_index('image_prefix', drop=False)\n",
    "df2 = df2[~df2.index.isin(google_automl_dataset.index)]\n",
    "assert len(df2) == len(df) - len(google_automl_dataset)\n",
    "\n",
    "df_cloud = df[df['has_cloud_and_shadow'] == 1]\n",
    "gam_cloud = google_automl_dataset[google_automl_dataset['label'] == 'has_cloud_and_shadow']\n",
    "df2_cloud = df2[df2['has_cloud_and_shadow'] == 1]\n",
    "assert len(pd.read_csv(root + '/patches_with_cloud_and_shadow.csv', header=None)) == len(df_cloud)           \n",
    "assert len(df_cloud) == len(df2_cloud) + len(gam_cloud)\n",
    "\n",
    "no_cloud_df2_sample = df2[df2['has_cloud_and_shadow'] == 0].sample(n=len(df2_cloud), random_state=random_seed)\n",
    "\n",
    "train, valid, test = balanced_class_train_test_splits(*[df2_cloud, no_cloud_df2_sample])\n",
    "train['set'] = 'TRAIN'\n",
    "valid['set'] = 'VALIDATION'\n",
    "test['set'] = 'TEST'\n",
    "\n",
    "google_automl_dataset_large = pd.concat([train, valid, test, google_automl_dataset])\n",
    "\n",
    "def set_label(row):\n",
    "    if row['label'] is np.nan:\n",
    "        row['label'] = 'has_cloud_and_shadow' if row['has_cloud_and_shadow'] == 1 else 'no_cloud_and_shadow'\n",
    "    return row\n",
    "\n",
    "google_automl_dataset_large = google_automl_dataset_large.apply(set_label, axis=1)\n",
    "google_automl_dataset_large['gcs_uri'] = 'gs://big_earth_automl/png_image_files_all_clouds_augmented/' + google_automl_dataset_large['image_prefix'] + '.png' \n",
    "\n",
    "assert len(google_automl_dataset_large[google_automl_dataset_large.duplicated()]) == 0\n",
    "for field in ['set', 'gcs_uri', 'label']:\n",
    "    assert len(google_automl_dataset_large[google_automl_dataset_large[field].isna()]) == 0\n",
    "    \n",
    "google_automl_dataset_large[['set', 'gcs_uri', 'label']].to_csv(root + '/google_automl_dataset_large.csv', index=False)\n",
    "len(google_automl_dataset_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9280 9280\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(google_automl_dataset_large[google_automl_dataset_large['label'] == 'has_cloud_and_shadow']),\n",
    "    len(google_automl_dataset_large[google_automl_dataset_large['label'] == 'no_cloud_and_shadow']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_files_from_tif_to_augmented_png(\\png_files_path, image_dir, image_prefixes,\n",
    "                                          image_suffix, augmentations):\n",
    "    if not os.path.exists(png_files_path):\n",
    "        os.mkdir(png_files_path)\n",
    "\n",
    "    def image_to_png(image_prefix):\n",
    "        bands = [np.asarray(\n",
    "            Image.open(f\"{image_dir}/{image_prefix}/{image_prefix}_B{band}.tif\"),\n",
    "            dtype=np.uint16) for band in [\"02\", \"03\", \"04\"]]\n",
    "\n",
    "        stacked_arr = np.stack(bands, axis=-1)\n",
    "\n",
    "        if augmentations is not None:\n",
    "            augmented_arr = augmentations(image=stacked_arr)['image']\n",
    "        else:\n",
    "            augmented_arr = stacked_arr\n",
    "        imageio.imwrite(im=augmented_arr, uri=f\"{png_files_path}/{image_prefix}{image_suffix}.png\",\n",
    "                        format='PNG-FI')\n",
    "\n",
    "    for image_prefix in image_prefixes:\n",
    "        image_to_png(image_prefix)\n",
    "            \n",
    "\n",
    "def augmented_png_dataset(dataset: pd.DataFrame()): \n",
    "    flip = Compose([ Flip(p=1) ]) \n",
    "    rotate = Compose([ Rotate(limit=(1, 360), p=1), ]) \n",
    "    flip_and_rotate = Compose([ Flip(p=1), Rotate(limit=(1, 360), p=1), ])\n",
    "    datasets = []\n",
    "    for augmentations, image_suffix in [(None, ''), (flip, '_flip'), (rotate, '_rotate'),\n",
    "                                       (flip_and_rotate, '_flip_and_rotate')]:\n",
    "        dataset_for_suffix = dataset.copy()\n",
    "        dataset_for_suffix['image_prefix'] = dataset_for_suffix['image_prefix'] + image_suffix\n",
    "        dataset_for_suffix = dataset_for_suffix.set_index('image_prefix', drop=False)\n",
    "        datasets.append(dataset_for_suffix)\n",
    "        image_files_from_tif_to_augmented_png(png_files_path=root + '/png_image_files_augmented', \n",
    "                                              image_dir=root + '/BigEarthNet-v1.0',\n",
    "            image_prefixes=dataset['image_prefix'].values, image_suffix=image_suffix,\n",
    "            augmentations=augmentations)\n",
    "\n",
    "    return pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_engineering.data_aggregator.parallelize import parallelize_task\n",
    "from albumentations import Compose, Flip, Rotate \n",
    "import imageio\n",
    "\n",
    "train_augmented = augmented_png_dataset(google_automl_dataset_large[google_automl_dataset_large['set'] == 'TRAIN']) \n",
    "valid_augmented = augmented_png_dataset(google_automl_dataset_large[google_automl_dataset_large['set'] == 'VALIDATION']) \n",
    "test = google_automl_dataset_large[google_automl_dataset_large['set'] == 'TEST']\n",
    "test['image_prefix'] = test['gcs_uri'].str.split('/').apply(lambda x: x[-1].replace(\".png\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_from_tif_to_augmented_png(\n",
    "    png_files_path=root + '/png_image_files_augmented', \n",
    "    image_dir=root + '/BigEarthNet-v1.0',\n",
    "    image_prefixes=test['image_prefix'].values, image_suffix='', augmentations=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_automl_dataset_large_aug = pd.concat([\n",
    "    train_augmented, \n",
    "    valid_augmented,\n",
    "    test])\n",
    "    \n",
    "assert (len(google_automl_dataset_large[google_automl_dataset_large['set'] == 'TRAIN']) * 4 + \n",
    "      len(google_automl_dataset_large[google_automl_dataset_large['set'] == 'VALIDATION']) * 4 +\n",
    "      len(test)) == len(google_automl_dataset_large_aug)\n",
    "assert len(google_automl_dataset_large_aug[google_automl_dataset_large_aug.duplicated()]) == 0\n",
    "\n",
    "google_automl_dataset_large_aug['gcs_uri'] = 'gs://big_earth_automl/png_image_files_augmented_large/' + google_automl_dataset_large_aug['image_prefix'] + \".png\"\n",
    "google_automl_dataset_large_aug[['set', 'gcs_uri', 'label']].to_csv(root + '/google_automl_dataset_large_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>gcs_uri</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68715</th>\n",
       "      <td>TEST</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68716</th>\n",
       "      <td>TEST</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68717</th>\n",
       "      <td>TEST</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68718</th>\n",
       "      <td>TEST</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68719</th>\n",
       "      <td>TEST</td>\n",
       "      <td>gs://big_earth_automl/png_image_files_au...</td>\n",
       "      <td>has_cloud_and_shadow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         set                                            gcs_uri  \\\n",
       "0      TRAIN  gs://big_earth_automl/png_image_files_au...   \n",
       "1      TRAIN  gs://big_earth_automl/png_image_files_au...   \n",
       "2      TRAIN  gs://big_earth_automl/png_image_files_au...   \n",
       "3      TRAIN  gs://big_earth_automl/png_image_files_au...   \n",
       "4      TRAIN  gs://big_earth_automl/png_image_files_au...   \n",
       "...      ...                                                ...   \n",
       "68715   TEST  gs://big_earth_automl/png_image_files_au...   \n",
       "68716   TEST  gs://big_earth_automl/png_image_files_au...   \n",
       "68717   TEST  gs://big_earth_automl/png_image_files_au...   \n",
       "68718   TEST  gs://big_earth_automl/png_image_files_au...   \n",
       "68719   TEST  gs://big_earth_automl/png_image_files_au...   \n",
       "\n",
       "                      label  \n",
       "0      has_cloud_and_shadow  \n",
       "1      has_cloud_and_shadow  \n",
       "2      has_cloud_and_shadow  \n",
       "3      has_cloud_and_shadow  \n",
       "4      has_cloud_and_shadow  \n",
       "...                     ...  \n",
       "68715  has_cloud_and_shadow  \n",
       "68716  has_cloud_and_shadow  \n",
       "68717  has_cloud_and_shadow  \n",
       "68718  has_cloud_and_shadow  \n",
       "68719  has_cloud_and_shadow  \n",
       "\n",
       "[18560 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_automl_dataset_large_aug[\n",
    "    (~google_automl_dataset_large_aug['gcs_uri'].str.contains('flip')) & (~google_automl_dataset_large_aug['gcs_uri'].str.contains('rotate'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29792.0\n",
      "3648.0\n",
      "920.0\n",
      "68720 68720\n"
     ]
    }
   ],
   "source": [
    "google_automl_dataset_large_aug = pd.read_csv(root + '/google_automl_dataset_large_aug.csv')\n",
    "print(len(google_automl_dataset_large_aug[google_automl_dataset_large_aug['set'] == 'TRAIN']) / 2)\n",
    "print(len(google_automl_dataset_large_aug[google_automl_dataset_large_aug['set'] == 'VALIDATION']) / 2)\n",
    "print(len(google_automl_dataset_large_aug[google_automl_dataset_large_aug['set'] == 'TEST']) / 2)\n",
    "print(len(google_automl_dataset_large_aug), len(pd.read_csv(root + '/google_automl_dataset_large_aug.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_augmented) / 2, len(valid_augmented) / 2, len(test) / 2)\n",
    "# google_automl_dataset_aug[google_automl_dataset_aug.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploaded missing test images\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/app/.gcs/credentials.json'\n",
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(\"big_earth_automl\")\n",
    "\n",
    "for path in test['image_prefix'].values:\n",
    "    file_path = root + '/png_image_files_augmented/' + path + '.png'\n",
    "    blob = bucket.blob('png_image_files_augmented_large/' + path + '.png')\n",
    "    blob.upload_from_filename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imageio.imread(root + '/png_image_files_augmented/S2B_MSIL2A_20180421T100031_7_89_flip.png',  format='PNG-FI')\n",
    "b = imageio.imread(root + '/png_image_files_augmented/S2B_MSIL2A_20180421T100031_7_89.png',  format='PNG-FI')\n",
    "assert (a[0][0] == b[-1][-1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sample_no_cloud_and_shadow) 1200 len(has_cloud_and_shadow) 1200\n",
      "len(train) 1905 len(valid) 253 len(test) 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "google_automl_dataset_dir = root + \"/data/big_earth\"\n",
    "\n",
    "if not os.path.exists(google_automl_dataset_dir):\n",
    "    os.mkdir(google_automl_dataset_dir)\n",
    "\n",
    "\n",
    "gcloud_vision_dataset = metadata[['image_prefix', 'has_cloud_and_shadow']]\n",
    "gcloud_vision_dataset['gcs_uri'] = (\"gs://big_earth_automl/png_image_files/\" +\n",
    "                                    gcloud_vision_dataset['image_prefix'] + \".png\")\n",
    "gcloud_vision_dataset['label'] = metadata.apply(\n",
    "    lambda row: 'has_cloud_and_shadow' if row['has_cloud_and_shadow'] == 1 else 'no_cloud_and_shadow', axis=1)\n",
    "\n",
    "has_cloud_and_shadow = gcloud_vision_dataset[gcloud_vision_dataset['has_cloud_and_shadow'] == 1].sample(\n",
    "    n=int(1000*1.2), random_state=random_seed\n",
    ")\n",
    "sample_no_cloud_and_shadow = gcloud_vision_dataset[gcloud_vision_dataset['has_cloud_and_shadow'] == 0].sample(\n",
    "    n=len(has_cloud_and_shadow))\n",
    "\n",
    "print(\"len(sample_no_cloud_and_shadow)\", len(sample_no_cloud_and_shadow), \"len(has_cloud_and_shadow)\", \n",
    "      len(has_cloud_and_shadow))\n",
    "\n",
    "train, valid, test = balanced_class_train_test_splits(*[sample_no_cloud_and_shadow, has_cloud_and_shadow])\n",
    "\n",
    "train['set'] = 'TRAIN'\n",
    "valid['set'] = 'VALIDATION'\n",
    "test['set'] = 'TEST'\n",
    "\n",
    "google_automl_dataset_csv_filepath = google_automl_dataset_dir + \"/google_automl_cloud_and_shadow_dataset_small.csv\"\n",
    "\n",
    "gcloud_vision_split_dataset = pd.concat([train, valid, test])[['set', 'gcs_uri', 'label']]\n",
    "# gcloud_vision_split_dataset.to_csv(google_automl_dataset_csv_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from hashlib import sha256\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from concurrent.futures import Future\n",
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "from typing import List\n",
    "    \n",
    "    \n",
    "def parallelize_task(num_workers, iterator, task, **task_kwargs):\n",
    "    chunk_size = len(iterator) // num_workers\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        tasks: List[Future] = []\n",
    "        start_index = 0\n",
    "        for x in range(num_workers):\n",
    "            end_index = min(start_index + chunk_size + 1, len(iterator))\n",
    "            chunk = iterator[start_index:end_index]\n",
    "            tasks.append(executor.submit(task, chunk, **task_kwargs))\n",
    "            start_index = end_index\n",
    "\n",
    "        return [task.result() for task in tasks]\n",
    "\n",
    "\n",
    "logger = logging.Logger(\"archive_etler\", level=logging.INFO)\n",
    "csv_files_path=csv_output_dir\n",
    "cloud_and_snow_csv_dir=root + \"/data/big_earth\"\n",
    "json_dir=json_files_dir               \n",
    "\n",
    "\n",
    "if not os.path.exists(csv_files_path):\n",
    "    os.mkdir(csv_files_path)\n",
    "\n",
    "# From BigEarth team: we used the same labels of the CORINE Land Cover program operated by the European Environment\n",
    "# Agency. You can check the label names from\n",
    "# https://land.copernicus.eu/user-corner/technical-library/corine-land-cover-nomenclature-guidelines/html/.\n",
    "replacements = {\n",
    "    'Bare rocks': 'Bare rock',\n",
    "    'Natural grasslands': 'Natural grassland',\n",
    "    'Peat bogs': 'Peatbogs',\n",
    "    'Transitional woodland-shrub': 'Transitional woodland/shrub'\n",
    "}\n",
    "\n",
    "def multi_replace(arr):\n",
    "    return [replacements[el] if replacements.get(el) is not None else el for el in arr]\n",
    "\n",
    "def read_and_augment_metadata(json_metadata_file, mlb):\n",
    "    with open(json_metadata_file) as fileobj:\n",
    "        obj = json.load(fileobj)\n",
    "        obj['labels'] = multi_replace(obj['labels'])\n",
    "        obj['labels_sha256_hexdigest'] = sha256('-'.join(obj['labels']).encode('utf-8')).hexdigest()\n",
    "        obj['binarized_labels'] = mlb.transform([obj['labels']])\n",
    "        obj['image_prefix'] = json_metadata_file.rsplit('/')[-2]\n",
    "        return obj\n",
    "\n",
    "def json_metadata_from_files(json_metadata_files, mlb):\n",
    "    return [read_and_augment_metadata(json_metadata_file, mlb) for json_metadata_file in json_metadata_files]\n",
    "\n",
    "start = time.time()\n",
    "# glob_path = json_dir + '/**/*.json'\n",
    "# paths = glob.glob(glob_path)\n",
    "imgs = [\"S2A_MSIL2A_20170613T101031_0_{}\".format(num) for num in range(45, 88)]\n",
    "paths = [json_dir + f'/{image}/{image}_labels_metadata.json' for image in imgs]\n",
    "logger.info(f\"Fetched {len(paths)} paths. in {time.time() - start} seconds.\")\n",
    "start = time.time()\n",
    "\n",
    "# 44 level 3 classes:\n",
    "# Currently using:\n",
    "# https://land.copernicus.eu/user-corner/technical-library/corine-land-cover-nomenclature-guidelines/html/\n",
    "classes = [\"Continuous urban fabric\", \"Discontinuous urban fabric\", \"Industrial or commercial units\",\n",
    "       \"Road and rail networks and associated land\", \"Port areas\", \"Airports\", \"Mineral extraction sites\",\n",
    "       \"Dump sites\",\n",
    "       \"Construction sites\", \"Green urban areas\", \"Sport and leisure facilities\", \"Non-irrigated arable land\",\n",
    "       \"Permanently irrigated land\", \"Rice fields\", \"Vineyards\", \"Fruit trees and berry plantations\",\n",
    "       \"Olive groves\",\n",
    "       \"Pastures\", \"Annual crops associated with permanent crops\", \"Complex cultivation patterns\",\n",
    "       \"Land principally occupied by agriculture, with significant areas of natural vegetation\",\n",
    "       \"Agro-forestry areas\",\n",
    "       \"Broad-leaved forest\", \"Coniferous forest\", \"Mixed forest\", \"Natural grassland\", \"Moors and heathland\",\n",
    "       \"Sclerophyllous vegetation\", \"Transitional woodland/shrub\", \"Beaches, dunes, sands\", \"Bare rock\",\n",
    "       \"Sparsely vegetated areas\", \"Burnt areas\", \"Glaciers and perpetual snow\", \"Inland marshes\", \"Peatbogs\",\n",
    "       \"Salt marshes\", \"Salines\", \"Intertidal flats\", \"Water courses\", \"Water bodies\", \"Coastal lagoons\",\n",
    "       \"Estuaries\",\n",
    "       \"Sea and ocean\"]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([classes])\n",
    "# sanity check the output\n",
    "logger.info(f\"Sea and ocean: {mlb.transform([['Sea and ocean']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_image_dir = os.path.join(root, \"data/big_earth/npy_image_files\")\n",
    "npy_files = os.listdir(npy_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab13b1c0f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_prefix = \"S2B_MSIL2A_20180224T112109_63_73\"\n",
    "\n",
    "filename = os.path.join(npy_image_dir, image_prefix + \".npy\")\n",
    "arr = np.load(filename)\n",
    "\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "\n",
    "def stats_for_tiff_images(filenames, use_test_data=False):\n",
    "    def read_image(filename, band, use_test_data):\n",
    "        filename = filename.format(band)\n",
    "        if use_test_data:\n",
    "            num = int(band)\n",
    "            band_shape = (120, 120)\n",
    "            return np.full(band_shape, num)\n",
    "        return imageio.imread(filename, format='TIFF')\n",
    "    \n",
    "    def images_for_band(band):\n",
    "        return np.stack([read_image(filename, band, use_test_data) for filename in filenames]).flatten()\n",
    "    \n",
    "    all_bands = np.stack([images_for_band(band) for band in [\"02\", \"03\", \"04\"]], axis=-1)\n",
    "    stats = defaultdict(dict)\n",
    "    for stat_name, stat_func in [('mean', np.mean), ('std', np.std), ('min', np.min), ('max', np.max)]:\n",
    "        stats[stat_name] = stat_func(all_bands, axis=0)\n",
    "    \n",
    "    return pd.DataFrame(stats, index=['red','blue', 'green'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_for_tiff_images_with_dask(filenames, use_test_data=False):\n",
    "    def read_image(filename, band, use_test_data):\n",
    "        filename = filename.format(band)\n",
    "        if use_test_data:\n",
    "            num = int(band)\n",
    "            band_shape = (120, 120)\n",
    "            return np.full(band_shape, num)\n",
    "        band_ds = rasterio.open(filename)\n",
    "        return np.array(band_ds.read(1))\n",
    "    \n",
    "    def images_for_band(band):\n",
    "        delayed_read = dask.delayed(read_image, pure=True)\n",
    "        lazy_images = [da.from_delayed(delayed_read(filename, band, use_test_data), dtype=np.uint16, shape=(120, 120))\n",
    "                       for filename in filenames]\n",
    "\n",
    "        stack = da.stack(lazy_images, axis=0).rechunk('auto')\n",
    "        return stack.flatten()\n",
    "    \n",
    "    all_bands = da.stack([images_for_band(\"02\"), images_for_band(\"03\"), images_for_band(\"04\")], axis=-1)\n",
    "    stats = defaultdict(dict)\n",
    "    for stat_name, stat_func in [('mean', da.mean), ('std', da.std), ('min', da.min), ('max', da.max)]:\n",
    "        stats[stat_name] = stat_func(all_bands, axis=0).compute()\n",
    "    \n",
    "    return pd.DataFrame(stats, index=['red','blue', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root + \"/Documents/bigearthnet-19-models/splits/train.csv\", header=None)\n",
    "files = [os.path.join(json_files_dir, file, f\"{file}_B{{}}.tif\") for file in train[0].values]\n",
    "import random\n",
    "indexes = [random.randint(0, len(files)) for _ in range(1000)]\n",
    "files = [files[index] for index in indexes]\n",
    "npy_files = [npy_image_dir + \"/\" + file.split(\"/\")[-2] + \".npy\" for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'mean': array([724.09112958, 863.22668444, 852.34654701])})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats_for_tiff_images(files, use_test_data=False)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'mean': array([724.09112958, 863.22668444, 852.34654701])})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dask = stats_for_tiff_images_with_dask(files, use_test_data=False)\n",
    "stats_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'mean': array([451.73882229, 633.5591625 , 616.8819859 ]),\n",
       "             'std': array([597.35456145, 599.67747276, 695.1632644 ]),\n",
       "             'min': array([0, 0, 0], dtype=uint16),\n",
       "             'max': array([17620, 18846, 16573], dtype=uint16)})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dask = stats_for_tiff_images_with_dask(files, use_test_data=False)\n",
    "stats_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_for_numpy_images(filenames, use_test_data=True):\n",
    "    def read_image(filename, use_test_data):\n",
    "        if use_test_data:\n",
    "            band_shape = (120, 120)\n",
    "            return np.stack([np.full(band_shape, num) for num in [1, 2, 3]], axis=-1)\n",
    "        return np.load(filename)\n",
    "\n",
    "    delayed_read = dask.delayed(read_image, pure=True)\n",
    "    lazy_images = [da.from_delayed(delayed_read(filename, use_test_data), dtype=np.uint16, shape=(120, 120, 3))\n",
    "                   for filename in filenames]\n",
    "\n",
    "    stack = da.stack(lazy_images, axis=0)\n",
    "    stack = stack.reshape(-1, stack.shape[-1]).rechunk('auto')\n",
    "    stats = defaultdict(dict)\n",
    "    for stat_name, stat_func in [('mean', da.mean), ('std', da.std), ('min', da.min), ('max', da.max)]:\n",
    "        stats[stat_name] = stat_func(stack, axis=0).compute()\n",
    "\n",
    "    return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.51993274688721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451.738822</td>\n",
       "      <td>597.354561</td>\n",
       "      <td>0</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633.559162</td>\n",
       "      <td>599.677473</td>\n",
       "      <td>0</td>\n",
       "      <td>18846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>616.881986</td>\n",
       "      <td>695.163264</td>\n",
       "      <td>0</td>\n",
       "      <td>16573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean         std  min    max\n",
       "0  451.738822  597.354561    0  17620\n",
       "1  633.559162  599.677473    0  18846\n",
       "2  616.881986  695.163264    0  16573"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "print(time.time() - start)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451.738822</td>\n",
       "      <td>597.354561</td>\n",
       "      <td>0</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633.559162</td>\n",
       "      <td>599.677473</td>\n",
       "      <td>0</td>\n",
       "      <td>18846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>616.881986</td>\n",
       "      <td>695.163264</td>\n",
       "      <td>0</td>\n",
       "      <td>16573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean         std  min    max\n",
       "0  451.738822  597.354561    0  17620\n",
       "1  633.559162  599.677473    0  18846\n",
       "2  616.881986  695.163264    0  16573"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  7,  9],\n",
       "       [ 3,  4, 10]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 7, 9], [3, 4, 10]])\n",
    "a.reshape(-1, a.shape[-1])\n",
    "\n",
    "# np.apply_along_axis(np.max, 1, a)\n",
    "# np.max(a, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'libfreeimage-3.16.0-linux64.so' was not found on your computer; downloading it now.\n",
      "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/freeimage/libfreeimage-3.16.0-linux64.so (4.6 MB)\n",
      "Downloading: 8192/4830080 bytes (0.2%884736/4830080 bytes (18.31425408/4830080 bytes (29.5%1916928/4830080 bytes (39.7%2359296/4830080 bytes (48.8%2908160/4830080 bytes (60.2%3391488/4830080 bytes (70.2%3883008/4830080 bytes (80.4%4374528/4830080 bytes (90.6%4830080/4830080 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /home/jovyan/.imageio/freeimage/libfreeimage-3.16.0-linux64.so.\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "imageio.plugins.freeimage.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3) uint16\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img_dir = root + \"/data/S2A_MSIL2A_20170613T101031_6_59\"\n",
    "\n",
    "def image_files_from_tif_to_npy(num_workers, npy_files_path, image_dir, image_prefixes):\n",
    "    if not os.path.exists(npy_files_path):\n",
    "        os.mkdir(npy_files_path)\n",
    "\n",
    "    def image_to_rgb_tiff(image_prefix):\n",
    "        # cv2 expects BGR format\n",
    "        bands = [cv2.imread(f\"{image_dir}/{image_prefix}/{image_prefix}_B{band}.tif\") \n",
    "                 for band in [\"04\", \"03\", \"02\"]]\n",
    "\n",
    "        stacked_arr = np.stack(bands, axis=-1)\n",
    "        return cv2.fromarray(stacked_arr)\n",
    "#         np.save(f\"{npy_files_path}/{image_prefix}\", stacked_arr)\n",
    "\n",
    "    def images_to_npy(image_prefixes):\n",
    "        for image_prefix in image_prefixes:\n",
    "            image_to_rgb_tiff(image_prefix)\n",
    "            \n",
    "# image_files_to_tiff_file(10, 'foo', root + \"/data\", [\"S2A_MSIL2A_20170613T101031_6_59\"])\n",
    "\n",
    "def image_to_rgb_tiff(image_prefix):    \n",
    "    bands = [np.asarray(\n",
    "        Image.open(f\"{root}/data/{image_prefix}/{image_prefix}_B{band}.tif\"),\n",
    "        dtype=np.uint16) for band in [\"04\", \"03\", \"02\"]]\n",
    "    \n",
    "    stacked_arr = np.stack(bands, axis=-1)\n",
    "    return stacked_arr\n",
    "#     cv2.imwrite('test.png', stacked_arr, \"flag\")\n",
    "\n",
    "arr = image_to_rgb_tiff(\"S2A_MSIL2A_20170613T101031_6_59\")\n",
    "print(arr.shape, arr.dtype)\n",
    "# https://github.com/imageio/imageio/issues/146\n",
    "imageio.imwrite(im=arr, uri='test.png', format='PNG-FI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_prefix = \"S2A_MSIL2A_20170613T101031_6_59\"\n",
    "band = \"02\"\n",
    "\n",
    "# img = cv2.imread(f\"{root}/data/{image_prefix}/{image_prefix}_B{band}.tif\", cv2.IMREAD_UNCHANGED)\n",
    "img = Image.open(f\"{root}/data/{image_prefix}/{image_prefix}_B{band}.tif\")\n",
    "max(img.getdata())\n",
    "# np.asarray(img)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[462, 427, 374, ..., 358, 370, 398],\n",
       "       [223, 271, 335, ..., 379, 374, 398],\n",
       "       [245, 258, 271, ..., 330, 385, 352],\n",
       "       ...,\n",
       "       [265, 275, 285, ..., 248, 234, 226],\n",
       "       [275, 272, 283, ..., 176, 218, 223],\n",
       "       [267, 284, 289, ..., 181, 226, 234]], dtype=uint16)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = f\"{root}/data/big_earth/BigEarthNet-v1.0/{image_prefix}/{image_prefix}_B{band}.tif\"\n",
    "# img = Image.open(file)\n",
    "# plt.imshow(img)\n",
    "img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show(command='fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('test.png').rsplit('/')[-1]\n",
    "(arr == imageio.imread('test.png', format='PNG-FI')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_image_dir = os.path.join(root, \"data/big_earth/npy_image_files\")\n",
    "npy_files = os.listdir(npy_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2B_MSIL2A_20180502T093039_63_58', '']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_files[0].rsplit('.npy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1ed4b4889b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{root}/data/big_earth/BigEarthNet-v1.0/{image_prefix}/{image_prefix}_B{band}.tif\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mband_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mband_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mband_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     print(band_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_writer_for_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/rasterio/path.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mParsedPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m\"\"\"The parsed path's original URI\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rasterio \n",
    "\n",
    "band = \"02\"\n",
    "for file in npy_files:\n",
    "    image_prefix = file.rsplit('.npy')[0]\n",
    "    file = f\"{root}/data/big_earth/BigEarthNet-v1.0/{image_prefix}/{image_prefix}_B{band}.tif\"\n",
    "    band_ds = rasterio.open(file)\n",
    "    band_data = band_ds.read(1)\n",
    "#     print(band_data)\n",
    "#     break\n",
    "#     img = Image.open(file)\n",
    "#     if max(img.getdata()) > 4096:\n",
    "#         print(min(img.getdata()), max(img.getdata))\n",
    "        \n",
    "    \n",
    "#     band_ds = gdal.Open(file,  gdal.GA_ReadOnly)\n",
    "#     raster_band = band_ds.GetRasterBand(1)\n",
    "#     band_data = raster_band.ReadAsArray()\n",
    "\n",
    "    \n",
    "\n",
    "#     img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "#     arr = np.asarray(img, dtype=np.uint16)\n",
    "#     path = os.path.join(npy_image_dir, file)\n",
    "#     arr = np.load(path)\n",
    "    arr = band_data\n",
    "    if arr.max() > 65536:\n",
    "        print(arr.min(), arr.max(), arr.mean())\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sha1:3c7269d160d4:00570cdecf26f9f06513c937911e3f6a4043f14b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.security import passwd\n",
    "passwd(\"you can do it 42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  has_snow\n",
      "image_prefix                              \n",
      "S2B_MSIL2A_20170831T095029_27_76         1\n",
      "S2B_MSIL2A_20170831T095029_27_85         1\n",
      "S2B_MSIL2A_20170831T095029_29_75         1\n",
      "\n",
      "\n",
      "                                  has_cloud_and_shadow\n",
      "image_prefix                                          \n",
      "S2A_MSIL2A_20170717T113321_35_89                     1\n",
      "S2A_MSIL2A_20170717T113321_39_84                     1\n",
      "S2B_MSIL2A_20171112T114339_0_13                      1\n"
     ]
    }
   ],
   "source": [
    "json_object_lists = parallelize_task(num_workers=20, iterator=paths, task=json_metadata_from_files, **dict(mlb=mlb))\n",
    "df = pd.concat([pd.DataFrame.from_records(json_object_list) for json_object_list in json_object_lists])\n",
    "# Check the dimensions\n",
    "logger.info(f\"len(df): {len(df)}, len(paths): {len(paths)}\")\n",
    "logger.info(f\"Read files into dataframe in {time.time() - start} seconds.\")\n",
    "\n",
    "# Denote if patch has snow and/or cloudsrandom_state\n",
    "snow = pd.read_csv(os.path.join(cloud_and_snow_csv_dir, 'patches_with_seasonal_snow.csv'), header=None, names=['image_prefix'])\n",
    "snow_col = 'has_snow'\n",
    "snow[snow_col] = 1\n",
    "snow = snow.set_index('image_prefix')\n",
    "\n",
    "clouds = pd.read_csv(os.path.join(cloud_and_snow_csv_dir, 'patches_with_cloud_and_shadow.csv'), header=None, names=['image_prefix'])\n",
    "cloud_col = 'has_cloud_and_shadow'\n",
    "clouds[cloud_col] = 1\n",
    "clouds = clouds.set_index('image_prefix')\n",
    "\n",
    "print(snow.head(3))\n",
    "len_snow = len(snow)\n",
    "print('\\n')\n",
    "print(clouds.head(3))\n",
    "len_clouds = len(clouds)\n",
    "\n",
    "for column in [snow_col, cloud_col]:\n",
    "    df[column] = 0\n",
    "\n",
    "df = df.set_index('image_prefix')\n",
    "df.update(snow)\n",
    "df.update(clouds)\n",
    "# assert df[snow_col].sum() == len_snow\n",
    "# assert df[cloud_col].sum() == len_clouds\n",
    "\n",
    "df.to_csv(csv_files_path + '/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "npy_files_path = f\"{root}/data/big_earth/npy_files\"\n",
    "if os.path.exists(npy_files_path):\n",
    "    os.rmdir(npy_files_path, recursive=True)\n",
    "os.mkdir(npy_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/home/jovyan/work/data/big_earth/metadatametadata.csv' does not exist: b'/home/jovyan/work/data/big_earth/metadatametadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-19b775046faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_output_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/home/jovyan/work/data/big_earth/metadatametadata.csv' does not exist: b'/home/jovyan/work/data/big_earth/metadatametadata.csv'"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(csv_output_dir + 'metadata.csv')\n",
    "dataset_size = len(metadata)\n",
    "sample_size = 20000\n",
    "frac = sample_size / dataset_size\n",
    "sample = metadata.sample(frac=frac, random_state=0)\n",
    "print(len(sample))\n",
    "\n",
    "def image_files_to_npy_file(image_prefix):\n",
    "    bands = [np.asarray(\n",
    "    Image.open(f\"{root}/data/big_earth/BigEarthNet-v1.0/{image_prefix}/{image_prefix}_B{band}.tif\"),\n",
    "    dtype=np.uint16) for band in [\"02\", \"03\", \"04\"]]\n",
    "    \n",
    "    stacked_arr = np.stack(bands, axis=-1)\n",
    "    np.save(f\"{npy_files_path}/{image_prefix}\", stacked_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "db.from_sequence(sample['image_prefix'].values, npartitions=50).map(image_files_to_npy_file).compute()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class AugmentedImageSequence(Sequence):\n",
    "    def __init__(self, x: np.array, y: np.array, batch_size, augmentations):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base_index = [idx for idx in range(len(x))]\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, batch_num):\n",
    "        if batch_num == 0:\n",
    "            print('getting batch_num', batch_num)\n",
    "            start = time.time()\n",
    "\n",
    "        batch_x = self.x[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "\n",
    "        if self.y is not None:\n",
    "            batch_y = self.y[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "\n",
    "        start = time.time()\n",
    "        images = self.batch_loader(batch_x)\n",
    "\n",
    "        # training\n",
    "        if self.y is not None:\n",
    "            batch_x = np.stack([self.augmentations(image=x)[\"image\"] for x in images], axis=0)\n",
    "\n",
    "            if batch_num == 0:\n",
    "                print('fetched batch_num', batch_num, 'in', time.time() - start, 'seconds')\n",
    "\n",
    "            return batch_x, batch_y\n",
    "        # test (inference only)\n",
    "        else:\n",
    "            return np.array(images)\n",
    "\n",
    "    def batch_loader(self, image_paths) -> np.array:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        shuffled_index = self.base_index.copy()\n",
    "        random.shuffle(shuffled_index)\n",
    "        self.x = self.x[shuffled_index]\n",
    "\n",
    "        if self.y is not None:\n",
    "            self.y = self.y[shuffled_index]\n",
    "\n",
    "class AugmentedImageSequenceFromNpy(AugmentedImageSequence):\n",
    "    def __init__(self, x: np.array, y: np.array, batch_size, augmentations):\n",
    "        super().__init__(x=x, y=y, batch_size=batch_size, augmentations=augmentations)\n",
    "\n",
    "    def batch_loader(self, image_paths) -> np.array:\n",
    "        return np.array([np.load(image_path) for image_path in image_paths])\n",
    "    \n",
    "    \n",
    "class AugmentedImageSequenceFromTiff(AugmentedImageSequence):\n",
    "    def __init__(self, x: np.array, y: np.array, batch_size, augmentations):\n",
    "        super().__init__(x=x, y=y, batch_size=batch_size, augmentations=augmentations)\n",
    "\n",
    "    def batch_loader(self, image_paths) -> np.array:\n",
    "        return np.array([self.load_image_bands_from_disk(image_path) for image_path in image_paths])\n",
    "\n",
    "    def load_image_bands_from_disk(self, base_filename):\n",
    "        bands = []\n",
    "        for band in [\"02\", \"03\", \"04\"]:\n",
    "            bands.append(np.array(Image.open(base_filename.format(band)), dtype=np.uint16))\n",
    "        return np.stack(bands, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, Flip, VerticalFlip, Resize, Rotate, ToFloat\n",
    ")\n",
    "import time\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    Flip(p=0.5),\n",
    "    Rotate(limit=(0, 360), p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_files_path = root + \"/data/big_earth/BigEarthNet-V1.0\"\n",
    "\n",
    "xtrain_npy = (npy_files_path + \"/\" + sample.iloc[:5000]['image_prefix'] + \".npy\").values\n",
    "xtrain_tiff = (tiff_files_path + \"/\" + sample.iloc[:5000]['image_prefix'] + \"/\" +\n",
    "               sample.iloc[:5000]['image_prefix'] + \"_B{}.tif\").values\n",
    "\n",
    "ytrain = np.array([np.random.randn(1, 44) for _ in range(len(xtrain))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "np_sequence = AugmentedImageSequenceFromNpy(x=xtrain_npy, y=ytrain, batch_size=batch_size,\n",
    "                                  augmentations=AUGMENTATIONS_TRAIN)\n",
    "tiff_sequence = AugmentedImageSequenceFromTiff(x=xtrain_tiff, y=ytrain, batch_size=batch_size,\n",
    "                                  augmentations=AUGMENTATIONS_TRAIN)\n",
    "\n",
    "def benchmark(sequence):\n",
    "    start = time.time()\n",
    "    for x, y in sequence:\n",
    "        # simulate training step\n",
    "        time.sleep(0.01)\n",
    "    print(\"finished epoch in\", time.time() - start, \"seconds\")\n",
    "\n",
    "print('np_sequence benchmark')\n",
    "benchmark(np_sequence)\n",
    "\n",
    "print('\\n')\n",
    "print('tiff sequence benchmark')\n",
    "benchmark(tiff_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
